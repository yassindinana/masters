 {
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment3-Task1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "egF4ticvxEsR",
        "outputId": "3837aadb-2171-49fb-af66-16141d3f2057"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "from collections import Counter\n",
        "from bs4 import BeautifulSoup\n",
        "import matplotlib\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "from contractions import contractions_dict\n",
        "import re\n",
        "import seaborn as sns\n",
        "import unicodedata\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.tokenize.toktok import ToktokTokenizer\n",
        "import spacy\n",
        "from spacy.lang.en import English\n",
        "nlp = spacy.load('en_core_web_sm', parse = False, tag = False, entity = False)\n",
        "import time\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import SGDClassifier, LogisticRegression"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ozvT2p2oxeU8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "2c46a699-b81e-40a5-d773-2c3290e38d5b"
      },
      "source": [
        "POSITIVE = pd.read_csv('/content/dataset/positive.csv', sep=',')\n",
        "NEGATIVE = pd.read_csv('/content/dataset/negative.csv', sep=',')\n",
        "rawData = pd.concat([POSITIVE, NEGATIVE],axis=0)\n",
        "rawData.head(5)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Review</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Better than Wolff's Kasha. I grew up eating Ka...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>It was such good product. Came in two differen...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>MMMM Yes all chocolate is good.&lt;br /&gt;But some ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>This is, as all of their cereals I've ordered ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Whoever Photoshopped the cookie on the front o...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              Review  Label\n",
              "0  Better than Wolff's Kasha. I grew up eating Ka...      1\n",
              "1  It was such good product. Came in two differen...      1\n",
              "2  MMMM Yes all chocolate is good.<br />But some ...      1\n",
              "3  This is, as all of their cereals I've ordered ...      1\n",
              "4  Whoever Photoshopped the cookie on the front o...      1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lszNyNx2k10c",
        "outputId": "beff7c86-45c3-44c2-abf8-f097b06caf20"
      },
      "source": [
        "print(\"The shape of the dataset is: \", rawData.shape)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The shape of the dataset is:  (50000, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aVG2eMbEyMzv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "8939f2d6-c86d-4dfd-9a1f-38d785d24b92"
      },
      "source": [
        "#Shuffling the values in the dataset\n",
        "rawData.sample(frac=1)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Review</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>20599</th>\n",
              "      <td>I have to buy this dog food for my Dashound be...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6994</th>\n",
              "      <td>well... it won't kill you. the flavor is good....</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3633</th>\n",
              "      <td>This is my favorite spicy mustard.  After a tr...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22501</th>\n",
              "      <td>I've been using this product for years, but th...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22084</th>\n",
              "      <td>I bought the tea for my mother who has asthma....</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3812</th>\n",
              "      <td>I looked forward to amazing popcorn... Instead...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17463</th>\n",
              "      <td>While I did not at any time imagine that I was...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7441</th>\n",
              "      <td>Before I get into my commentary about the Orij...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>541</th>\n",
              "      <td>The item is different from the one that bought...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18283</th>\n",
              "      <td>I really cannot give this product a bad review...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>50000 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  Review  Label\n",
              "20599  I have to buy this dog food for my Dashound be...      1\n",
              "6994   well... it won't kill you. the flavor is good....      0\n",
              "3633   This is my favorite spicy mustard.  After a tr...      0\n",
              "22501  I've been using this product for years, but th...      0\n",
              "22084  I bought the tea for my mother who has asthma....      1\n",
              "...                                                  ...    ...\n",
              "3812   I looked forward to amazing popcorn... Instead...      0\n",
              "17463  While I did not at any time imagine that I was...      1\n",
              "7441   Before I get into my commentary about the Orij...      0\n",
              "541    The item is different from the one that bought...      0\n",
              "18283  I really cannot give this product a bad review...      0\n",
              "\n",
              "[50000 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Cixf0_rekWE",
        "outputId": "63583e1f-91d0-4d36-8484-25c6a0989811"
      },
      "source": [
        "Counter(\" \".join(rawData[\"Review\"]).split()).most_common(10)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('the', 156501),\n",
              " ('I', 130866),\n",
              " ('and', 107416),\n",
              " ('a', 103296),\n",
              " ('to', 91397),\n",
              " ('of', 74159),\n",
              " ('is', 62916),\n",
              " ('it', 59766),\n",
              " ('this', 46084),\n",
              " ('in', 46005)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KmC9QEYHe_em",
        "outputId": "c1a60654-859d-4d11-d3f9-8660683a81c7"
      },
      "source": [
        "rawData.isnull().sum()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Review    0\n",
              "Label     0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OY1KNwyrJJeb",
        "outputId": "f69c904d-46a6-41f8-e545-9acb60516884"
      },
      "source": [
        "rawData.info()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 50000 entries, 0 to 24999\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   Review  50000 non-null  object\n",
            " 1   Label   50000 non-null  int64 \n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 1.1+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u6RhYf4yJNwR",
        "outputId": "fae2a88b-2b92-4a97-b1f0-55e6b167e61f"
      },
      "source": [
        "rawData['Label'].unique()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "id": "edCeebESJQ7w",
        "outputId": "6af079ca-b084-4781-c493-1fb5465ca8c4"
      },
      "source": [
        "sns.displot(rawData)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<seaborn.axisgrid.FacetGrid at 0x7fed54cd1438>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 422.875x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_u0HzesJRBR"
      },
      "source": [
        "def strip_html_tags(text):\n",
        "    soup = BeautifulSoup(text, \"html.parser\")\n",
        "    stripped_text = soup.get_text()\n",
        "    return stripped_text"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uJaNMdLAQP6H",
        "outputId": "da0df0f0-9839-4ed4-debf-35a87afa22a9"
      },
      "source": [
        "print(NEGATIVE['Review'][7])\n",
        "Testtext = strip_html_tags(NEGATIVE['Review'][7])\n",
        "print('-'*150)\n",
        "print(Testtext)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The previous reviewer is totally on point. Watery, not cheesy, very hot.<br /><br />So, the only thing they got right was the \"hot.\" Flavor is horrible, texture is nasty ( not cheesy yumnmy).<br /><br />Skip it, and you won't regret wasting your money the way I did. These went in the trash.<br /><br />Mir\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "The previous reviewer is totally on point. Watery, not cheesy, very hot.So, the only thing they got right was the \"hot.\" Flavor is horrible, texture is nasty ( not cheesy yumnmy).Skip it, and you won't regret wasting your money the way I did. These went in the trash.Mir\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQxYkC_KJRFD"
      },
      "source": [
        "def remove_special_characters(text):\n",
        "    text = re.sub('[^a-zA-z0-9\\s]', '', text)\n",
        "    return text"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lZuKJO8AS0XT",
        "outputId": "11a1b521-17d0-494b-b973-fcd480db8a4e"
      },
      "source": [
        "print(POSITIVE['Review'][337])\n",
        "Testtext = remove_special_characters(POSITIVE['Review'][337])\n",
        "print('-'*150)\n",
        "print(Testtext)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I recently bought the <a href=\"http://www.amazon.com/gp/product/B000VX7VJO\">Breville BKC600XL Gourmet Single-Cup Coffee Brewer</a>, which I love, and found a wide variety of 5 pack K-Cup samplers at Keurig.com.  <a href=\"http://www.amazon.com/gp/product/B000J4IDP6\">Gloria Jean's Coffee, Mudslide, K-Cups for Keurig Brewers, 25-Count Boxes (Pack of 2)</a> was in the Flavored Coffee sampler and there's one word that says how I feel about it - YUM! I used the 9 oz setting, which worked well, and the smell coming out of the brewer was heavenly. It has a very rich chocolate taste that reminded me of brownies and fudge. I added a little Coffee Mate Vanilla creamer and a shot of DeKuyper Butterscotch Schnapps - wow! It was so good I could have drank three of them. Unfortunately there was only one, but there will be more in a few days when the two boxes I ordered arrive!\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "I recently bought the a hrefhttpwwwamazoncomgpproductB000VX7VJOBreville BKC600XL Gourmet SingleCup Coffee Brewera which I love and found a wide variety of 5 pack KCup samplers at Keurigcom  a hrefhttpwwwamazoncomgpproductB000J4IDP6Gloria Jeans Coffee Mudslide KCups for Keurig Brewers 25Count Boxes Pack of 2a was in the Flavored Coffee sampler and theres one word that says how I feel about it  YUM I used the 9 oz setting which worked well and the smell coming out of the brewer was heavenly It has a very rich chocolate taste that reminded me of brownies and fudge I added a little Coffee Mate Vanilla creamer and a shot of DeKuyper Butterscotch Schnapps  wow It was so good I could have drank three of them Unfortunately there was only one but there will be more in a few days when the two boxes I ordered arrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TsK7XDs8JRH7"
      },
      "source": [
        "def expand_contractions(text, contraction_mapping=contractions_dict):\n",
        "    \n",
        "    contractions_pattern = re.compile('({})'.format('|'.join(contractions_dict.keys())), \n",
        "                                      flags=re.IGNORECASE|re.DOTALL)\n",
        "\n",
        "    def expand_match(contraction):\n",
        "        match = contraction.group(0)\n",
        "        first_char = match[0]\n",
        "        expanded_contraction = contraction_mapping.get(match) if contraction_mapping.get(match) else contraction_mapping.get(match.lower())                               \n",
        "        return first_char+expanded_contraction[1:] if expanded_contraction != None else match\n",
        "        \n",
        "    expanded_text = contractions_pattern.sub(expand_match, text)\n",
        "    expanded_text = re.sub(\"'\", \"\", expanded_text)\n",
        "    return expanded_text"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xpZTkr5yV15S",
        "outputId": "8b27efd5-4244-4880-d5cf-8818950b383f"
      },
      "source": [
        "print(POSITIVE['Review'][342])\n",
        "Testtext = expand_contractions(POSITIVE['Review'][342])\n",
        "print('-'*150)\n",
        "print(Testtext)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I've been eating Nagatanien Ochazuke Nori since I was a little girl.  I'm now 44 years old and still find the product delicious and satisfying!  It is way cheaper to purchase the 30-pack of Ochazuke vs buying it per pack at my local Asian store.  Me/my family use maybe a pack every week or so (each pack contains 3 envelopes).  When my kids have friends over when we happen to serve white rice for dinner with this ochazuke as a topping, the friends initially have a 'yuck' reaction when we tell them it contains seaweed.  However, once they taste it they usually have seconds!\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "I have been eating Nagatanien Ochazuke Nori since I was a little girl.  I am now 44 years old and still find the product delicious and satisfying!  It is way cheaper to purchase the 30-pack of Ochazuke vs buying it per pack at my local Asian store.  Me/my family use maybe a pack every week or so (each pack contains 3 envelopes).  When my kids have friends over when we happen to serve white rice for dinner with this ochazuke as a topping, the friends initially have a yuck reaction when we tell them it contains seaweed.  However, once they taste it they usually have seconds!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQuHBcr9JYXU"
      },
      "source": [
        "def lemmatize_text(text):\n",
        "    text = nlp(text)\n",
        "    return ' '.join([word.lemma_ if word.lemma_ != '-PRON-' else word.text for word in text])"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_b0lNssYJYaL"
      },
      "source": [
        "stopword_list = nltk.corpus.stopwords.words('english')\n",
        "stopword_list.remove('no')\n",
        "stopword_list.remove('not')\n",
        "\n",
        "def remove_stopwords(text, is_lower_case=False):\n",
        "    tokenizer = ToktokTokenizer()\n",
        "    tokens = tokenizer.tokenize(text)\n",
        "    tokens = [token.strip() for token in tokens]\n",
        "    \n",
        "    if is_lower_case:\n",
        "        filtered_tokens = [token for token in tokens if token not in stopword_list]\n",
        "    else:\n",
        "        filtered_tokens = [token for token in tokens if token.lower() not in stopword_list]\n",
        "    filtered_text = ' '.join(filtered_tokens)    \n",
        "    return filtered_text\n"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MqyyRRlgZbPj",
        "outputId": "49b06ee3-b4c1-40e3-dcb8-8440ab715001"
      },
      "source": [
        "print(POSITIVE['Review'][328])\n",
        "Testtext = remove_stopwords(POSITIVE['Review'][328])\n",
        "print('-'*150)\n",
        "print(Testtext)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I haven't used the honey in my granola yet which is why I purchased in the first place.  I did taste and try it in my spaghetti sauce and felt that it tasted very good.  The one thing is that it has a very strong honey taste which makes it have that pure taste to me.  My store bought honey was good but until I tried the Tropic Bee did I realize the difference was in the strength of the honey taste.  It's mild as far as not having that after taste of foods that are stronger in intensity from being a pure source of whatever it was taken from.  A good buy as far as I can tell.  I can't wait to make my granola bars to see if I get a sweeter taste than what I was getting with my store bought honey.\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "' used honey granola yet purchased first place. taste try spaghetti sauce felt tasted good. one thing strong honey taste makes pure taste me. store bought honey good tried Tropic Bee realize difference strength honey taste. ' mild far not taste foods stronger intensity pure source whatever taken from. good buy far tell. ' wait make granola bars see get sweeter taste getting store bought honey .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FwmLnGmCJYc2"
      },
      "source": [
        "def normalize_corpus(corpus, html_stripping=True, contraction_expansion=True,\n",
        "                     accented_char_removal=True, text_lower_case=True, \n",
        "                     text_lemmatization=True, special_char_removal=True, \n",
        "                     stopword_removal=True):\n",
        "    \n",
        "    normalized_corpus = []\n",
        "    # normalize each document in the corpus\n",
        "    for doc in corpus:\n",
        "        # strip HTML\n",
        "        if html_stripping:\n",
        "            doc = strip_html_tags(doc)\n",
        "        # remove accented characters\n",
        "        if accented_char_removal:\n",
        "            doc = remove_accented_chars(doc)\n",
        "        # expand contractions    \n",
        "        if contraction_expansion:\n",
        "            doc = expand_contractions(doc)\n",
        "        # lowercase the text    \n",
        "        if text_lower_case:\n",
        "            doc = doc.lower()\n",
        "        # remove extra newlines\n",
        "        doc = re.sub(r'[\\r|\\n|\\r\\n]+', ' ',doc)\n",
        "        # insert spaces between special characters to isolate them    \n",
        "        special_char_pattern = re.compile(r'([{.(-)!}])')\n",
        "        doc = special_char_pattern.sub(\" \\\\1 \", doc)\n",
        "        # lemmatize text\n",
        "        if text_lemmatization:\n",
        "            doc = lemmatize_text(doc)\n",
        "        # remove special characters    \n",
        "        if special_char_removal:\n",
        "            doc = remove_special_characters(doc)  \n",
        "        # remove extra whitespace\n",
        "        doc = re.sub(' +', ' ', doc)\n",
        "        # remove stopwords\n",
        "        if stopword_removal:\n",
        "            doc = remove_stopwords(doc, is_lower_case=text_lower_case)\n",
        "            \n",
        "        normalized_corpus.append(doc)\n",
        "    return normalized_corpus"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_3qqRUiJYfk"
      },
      "source": [
        "#rawData['Review'] = normalize_corpus(rawData.Review)\n",
        "#rawData.to_csv(\"normalized_food_reviews.csv\", index = False)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "W70dlBT0JYie",
        "outputId": "feec247e-9917-4682-ca39-795577faf16a"
      },
      "source": [
        "normalized_food_reviews = pd.read_csv('/content/normalized_food_reviews.csv')\n",
        "normalized_food_reviews.head(5)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Review</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>well wolff kasha grow eat kasha easy prepare h...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>good product come two different box describe c...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>mmmm yes chocolate good chocolate well well ch...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>cereal order far fresh high quality wonderful ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>whoever photoshoppe cookie front package true ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              Review  Label\n",
              "0  well wolff kasha grow eat kasha easy prepare h...      1\n",
              "1  good product come two different box describe c...      1\n",
              "2  mmmm yes chocolate good chocolate well well ch...      1\n",
              "3  cereal order far fresh high quality wonderful ...      1\n",
              "4  whoever photoshoppe cookie front package true ...      1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uC7tA7_SPbn9"
      },
      "source": [
        "normalized_food_reviews = pd.read_csv(\"/content/normalized_food_reviews.csv\")\n",
        "numberOfReviews=35000\n",
        "reviews = np.array(normalized_food_reviews['Review'].iloc[:numberOfReviews])\n",
        "Label = np.array(normalized_food_reviews['Label'].iloc[:numberOfReviews])\n",
        "\n",
        "# extract data for model evaluation\n",
        "train_reviews, test_reviews, train_Label, test_Label = train_test_split(reviews, Label, test_size=0.3)\n",
        "\n",
        "# build BOW features on train reviews\n",
        "cv = CountVectorizer(binary=False, min_df=0.0, max_df=1.0, ngram_range=(1,2))\n",
        "cv_train_features = cv.fit_transform(train_reviews)\n",
        "\n",
        "# build TFIDF features on train reviews\n",
        "tv = TfidfVectorizer(use_idf=True, min_df=0.0, max_df=1.0, ngram_range=(1,2),sublinear_tf=True)\n",
        "tv_train_features = tv.fit_transform(train_reviews)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1zt7ZgKcRkQE"
      },
      "source": [
        "cv_test_features = cv.transform(test_reviews)\n",
        "tv_test_features = tv.transform(test_reviews)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CHyLitR_Tnq1",
        "outputId": "d6ad6d2b-705c-484f-bfb8-d5d2a2390c50"
      },
      "source": [
        "print('BOW model:> Train features shape:', cv_train_features.shape, ' Test features shape:', cv_test_features.shape)\n",
        "print('TFIDF model:> Train features shape:', tv_train_features.shape, ' Test features shape:', tv_test_features.shape)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BOW model:> Train features shape: (24500, 477180)  Test features shape: (10500, 477180)\n",
            "TFIDF model:> Train features shape: (24500, 477180)  Test features shape: (10500, 477180)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2elYFULWUKb0"
      },
      "source": [
        "# We define our SVM and LR models\n",
        "lr = LogisticRegression(penalty='l2', max_iter=1000, C=1)\n",
        "svm = SGDClassifier(loss='hinge', max_iter=100)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "_u5Pm5P3TpWa",
        "outputId": "7cd1f908-b1c9-4411-fb47-9aa9f69ce05e"
      },
      "source": [
        "# Logistic Regression model on BOW features\n",
        "lr.fit(cv_train_features, train_Label)\n",
        "y_predicted = lr.predict(cv_test_features)\n",
        "\n",
        "print(\"The model accuracy score is: {}\".format(accuracy_score(test_Label, y_predicted)))\n",
        "print(\"The model precision score is: {}\".format(precision_score(test_Label, y_predicted, average=\"weighted\")))\n",
        "print(\"The model recall score is: {}\".format(recall_score(test_Label, y_predicted, average=\"weighted\")))\n",
        "print(\"The model F1-score is: {}\".format(f1_score(test_Label, y_predicted, average=\"weighted\")))\n",
        "\n",
        "print(classification_report(test_Label, y_predicted))\n",
        "\n",
        "display(pd.DataFrame(confusion_matrix(test_Label, y_predicted), columns=[\"Pred. negative\", \"Pred. positive\"], index=[\"Act. negative\", \"Act. positive\"]))"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model accuracy score is: 0.6666666666666666\n",
            "The model precision score is: 0.5996828523031845\n",
            "The model recall score is: 0.6666666666666666\n",
            "The model F1-score is: 0.6182174293302882\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.30      0.13      0.18      2973\n",
            "           1       0.72      0.88      0.79      7527\n",
            "\n",
            "    accuracy                           0.67     10500\n",
            "   macro avg       0.51      0.50      0.49     10500\n",
            "weighted avg       0.60      0.67      0.62     10500\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pred. negative</th>\n",
              "      <th>Pred. positive</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Act. negative</th>\n",
              "      <td>388</td>\n",
              "      <td>2585</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Act. positive</th>\n",
              "      <td>915</td>\n",
              "      <td>6612</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               Pred. negative  Pred. positive\n",
              "Act. negative             388            2585\n",
              "Act. positive             915            6612"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 524
        },
        "id": "2bim9anjT_cr",
        "outputId": "809ecaca-5efb-4fde-bcab-02f000dd9d5a"
      },
      "source": [
        "# Logistic Regression model on TF-IDF features\n",
        "lr.fit(cv_train_features, train_Label)\n",
        "y_predicted = lr.predict(tv_test_features)\n",
        "\n",
        "print(\"The model accuracy score is: {}\".format(accuracy_score(test_Label, y_predicted)))\n",
        "print(\"The model precision score is: {}\".format(precision_score(test_Label, y_predicted, average=\"weighted\")))\n",
        "print(\"The model recall score is: {}\".format(recall_score(test_Label, y_predicted, average=\"weighted\")))\n",
        "print(\"The model F1-score is: {}\".format(f1_score(test_Label, y_predicted, average=\"weighted\")))\n",
        "\n",
        "print(classification_report(test_Label, y_predicted))\n",
        "\n",
        "display(pd.DataFrame(confusion_matrix(test_Label, y_predicted), columns=[\"Pred. negative\", \"Pred. positive\"], index=[\"Act. negative\", \"Act. positive\"]))"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model accuracy score is: 0.7168571428571429\n",
            "The model precision score is: 0.5138841632653062\n",
            "The model recall score is: 0.7168571428571429\n",
            "The model F1-score is: 0.5986335734493499\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00      2973\n",
            "           1       0.72      1.00      0.84      7527\n",
            "\n",
            "    accuracy                           0.72     10500\n",
            "   macro avg       0.36      0.50      0.42     10500\n",
            "weighted avg       0.51      0.72      0.60     10500\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-57-3c0d6d256901>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_Label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_predicted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_Label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_predicted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Pred. negative\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Pred. positive\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Act. negative\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Act. positive\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not callable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "4ZH59U4VaIZx",
        "outputId": "1936a9ff-0e83-4908-863b-39a2e14c7ff3"
      },
      "source": [
        "# SVM model on BOW\n",
        "svm.fit(cv_train_features,train_Label)\n",
        "y_predicted = svm.predict(cv_test_features)\n",
        "\n",
        "print(\"The model accuracy score is: {}\".format(accuracy_score(test_Label, y_predicted)))\n",
        "print(\"The model precision score is: {}\".format(precision_score(test_Label, y_predicted, average=\"weighted\")))\n",
        "print(\"The model recall score is: {}\".format(recall_score(test_Label, y_predicted, average=\"weighted\")))\n",
        "print(\"The model F1-score is: {}\".format(f1_score(test_Label, y_predicted, average=\"weighted\")))\n",
        "\n",
        "print(classification_report(test_Label, y_predicted))\n",
        "\n",
        "display(pd.DataFrame(confusion_matrix(test_Label, y_predicted), columns=[\"Pred. negative\", \"Pred. positive\"], index=[\"Act. negative\", \"Act. positive\"]))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model accuracy score is: 0.8635238095238095\n",
            "The model precision score is: 0.8614576698683353\n",
            "The model recall score is: 0.8635238095238095\n",
            "The model F1-score is: 0.8621291425247117\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.73      0.76      3058\n",
            "           1       0.89      0.92      0.90      7442\n",
            "\n",
            "    accuracy                           0.86     10500\n",
            "   macro avg       0.84      0.83      0.83     10500\n",
            "weighted avg       0.86      0.86      0.86     10500\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pred. negative</th>\n",
              "      <th>Pred. positive</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Act. negative</th>\n",
              "      <td>2242</td>\n",
              "      <td>816</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Act. positive</th>\n",
              "      <td>617</td>\n",
              "      <td>6825</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               Pred. negative  Pred. positive\n",
              "Act. negative            2242             816\n",
              "Act. positive             617            6825"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "cYJLNk93a32g",
        "outputId": "2f86fa9e-c642-46c6-ad43-f8e508bc6bc1"
      },
      "source": [
        "#SVM model on TF-IDF\n",
        "svm.fit(tv_train_features,train_Label)\n",
        "y_predicted = svm.predict(tv_test_features)\n",
        "\n",
        "print(\"The model accuracy score is: {}\".format(accuracy_score(test_Label, y_predicted)))\n",
        "print(\"The model precision score is: {}\".format(precision_score(test_Label, y_predicted, average=\"weighted\")))\n",
        "print(\"The model recall score is: {}\".format(recall_score(test_Label, y_predicted, average=\"weighted\")))\n",
        "print(\"The model F1-score is: {}\".format(f1_score(test_Label, y_predicted, average=\"weighted\")))\n",
        "\n",
        "print(classification_report(test_Label, y_predicted))\n",
        "\n",
        "display(pd.DataFrame(confusion_matrix(test_Label, y_predicted), columns=[\"Pred. negative\", \"Pred. positive\"], index=[\"Act. negative\", \"Act. positive\"]))"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model accuracy score is: 0.8681904761904762\n",
            "The model precision score is: 0.8678808531033733\n",
            "The model recall score is: 0.8681904761904762\n",
            "The model F1-score is: 0.862000289521294\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.65      0.74      3058\n",
            "           1       0.87      0.96      0.91      7442\n",
            "\n",
            "    accuracy                           0.87     10500\n",
            "   macro avg       0.87      0.80      0.83     10500\n",
            "weighted avg       0.87      0.87      0.86     10500\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pred. negative</th>\n",
              "      <th>Pred. positive</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Act. negative</th>\n",
              "      <td>1984</td>\n",
              "      <td>1074</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Act. positive</th>\n",
              "      <td>310</td>\n",
              "      <td>7132</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               Pred. negative  Pred. positive\n",
              "Act. negative            1984            1074\n",
              "Act. positive             310            7132"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PjoS9LufbDcd",
        "outputId": "9d7cb375-e64f-4322-8521-8fdc4bd5239e"
      },
      "source": [
        "#ML MODELS LIBRARIES\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from nltk.tokenize.toktok import ToktokTokenizer\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, Dropout, SpatialDropout1D\n",
        "from tensorflow.keras.layers import LSTM\n",
        "\n",
        "\n",
        "le = LabelEncoder()\n",
        "tokenizer = ToktokTokenizer()\n",
        "\n",
        "normalized_food_reviews = pd.read_csv(\"/content/normalized_food_reviews.csv\")\n",
        "numberOfReviews=35000\n",
        "reviews = np.array(normalized_food_reviews['Review'].iloc[:numberOfReviews])\n",
        "Label = np.array(normalized_food_reviews['Label'].iloc[:numberOfReviews])\n",
        "\n",
        "# extract data for model evaluation\n",
        "train_reviews, test_reviews, train_Label, test_Label = train_test_split(reviews, Label, test_size=0.3)\n",
        "\n",
        "\n",
        "# tokenize reviews\n",
        "tokenized_train = [tokenizer.tokenize(text) for text in train_reviews]\n",
        "tokenized_test = [tokenizer.tokenize(text) for text in test_reviews]\n",
        "\n",
        "#Building word to index vocabulary\n",
        "token_counter = Counter([token for review in tokenized_train for token in review])\n",
        "vocab_map = {item[0]: index+1 for index, item in enumerate(dict(token_counter).items())}\n",
        "max_index = np.max(list(vocab_map.values()))\n",
        "vocab_map['PAD_INDEX'] = 0\n",
        "vocab_map['NOT_FOUND_INDEX'] = max_index+1\n",
        "vocab_size = len(vocab_map)\n",
        "# view vocabulary size and part of the vocabulary map\n",
        "print('Vocabulary Size:', vocab_size)\n",
        "print('Sample slice of vocabulary map:', dict(list(vocab_map.items())[10:20]))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocabulary Size: 27300\n",
            "Sample slice of vocabulary map: {'egg': 11, 'milk': 12, 'butter': 13, 'oil': 14, 'raisin': 15, 'caraway': 16, 'seed': 17, 'orange': 18, 'rind': 19, 'great': 20}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mTOrcPQCdkYR",
        "outputId": "66f8639a-e8b6-4713-8ec6-507ca6842a4f"
      },
      "source": [
        "# get max length of train corpus and initialize label encoder\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "\n",
        "le = LabelEncoder()\n",
        "max_len = np.max([len(review) for review in tokenized_train])\n",
        "\n",
        "# Convert tokenized text reviews to numeric vectors\n",
        "train_X = [[vocab_map[token] for token in tokenized_review] for tokenized_review in tokenized_train]\n",
        "train_X = sequence.pad_sequences(train_X, maxlen=max_len) # pad \n",
        "test_X = [[vocab_map[token] if vocab_map.get(token) else vocab_map['NOT_FOUND_INDEX'] \n",
        "           for token in tokenized_review] \n",
        "              for tokenized_review in tokenized_test]\n",
        "test_X = sequence.pad_sequences(test_X, maxlen=max_len)\n",
        "\n",
        "# Convert text sentiments into binary encodings\n",
        "train_y = le.fit_transform(train_Label)\n",
        "test_y = le.transform(test_Label)\n",
        "\n",
        "print('Max length of train review vectors:', max_len)\n",
        "print('Train review vectors shape:', train_X.shape, ' Test review vectors shape:', test_X.shape)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max length of train review vectors: 886\n",
            "Train review vectors shape: (24500, 886)  Test review vectors shape: (10500, 886)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BLZazetZd3LX"
      },
      "source": [
        "EMBEDDING_DIM = 128 # dimension for dense embeddings for each token\n",
        "LSTM_DIM = 64 # total LSTM units\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=vocab_size, output_dim=EMBEDDING_DIM, input_length=max_len))\n",
        "model.add(SpatialDropout1D(0.2))\n",
        "model.add(LSTM(LSTM_DIM, dropout=0.2, recurrent_dropout=0.2))\n",
        "model.add(Dense(1, activation=\"sigmoid\"))\n",
        "\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\",metrics=[\"accuracy\"])"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zkcs3-b0eENI",
        "outputId": "afe866e1-1746-444a-ca20-ff328711faeb"
      },
      "source": [
        "print(model.summary())"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 886, 128)          3494400   \n",
            "_________________________________________________________________\n",
            "spatial_dropout1d (SpatialDr (None, 886, 128)          0         \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 64)                49408     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 3,543,873\n",
            "Trainable params: 3,543,873\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "22gupen9eWVl",
        "outputId": "50fb169c-aab7-41fb-924e-2d16ffee09a3"
      },
      "source": [
        "# Plotting librairies\n",
        "from IPython.display import SVG\n",
        "SVG(tf.keras.utils.model_to_dot(model, show_shapes=True, show_layer_names=False, rankdir='LR', dpi=60).create(prog='dot', format='svg'))"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.SVG object>"
            ],
            "image/svg+xml": "<svg height=\"65pt\" viewBox=\"0.00 0.00 1131.00 78.00\" width=\"942pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g class=\"graph\" id=\"graph0\" transform=\"scale(.8333 .8333) rotate(0) translate(4 74)\">\n<title>G</title>\n<polygon fill=\"#ffffff\" points=\"-4,4 -4,-74 1127,-74 1127,4 -4,4\" stroke=\"transparent\"/>\n<!-- 140655425221912 -->\n<g class=\"node\" id=\"node1\">\n<title>140655425221912</title>\n<polygon fill=\"none\" points=\"0,-.5 0,-69.5 192,-69.5 192,-.5 0,-.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"96\" y=\"-54.3\">InputLayer</text>\n<polyline fill=\"none\" points=\"0,-46.5 192,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"46\" y=\"-31.3\">input:</text>\n<polyline fill=\"none\" points=\"92,-23.5 92,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"142\" y=\"-31.3\">output:</text>\n<polyline fill=\"none\" points=\"0,-23.5 192,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"48\" y=\"-8.3\">[(None, 886)]</text>\n<polyline fill=\"none\" points=\"96,-.5 96,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"144\" y=\"-8.3\">[(None, 886)]</text>\n</g>\n<!-- 140655425221520 -->\n<g class=\"node\" id=\"node2\">\n<title>140655425221520</title>\n<polygon fill=\"none\" points=\"228,-.5 228,-69.5 432,-69.5 432,-.5 228,-.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"330\" y=\"-54.3\">Embedding</text>\n<polyline fill=\"none\" points=\"228,-46.5 432,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"277\" y=\"-31.3\">input:</text>\n<polyline fill=\"none\" points=\"326,-23.5 326,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"379\" y=\"-31.3\">output:</text>\n<polyline fill=\"none\" points=\"228,-23.5 432,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"271.5\" y=\"-8.3\">(None, 886)</text>\n<polyline fill=\"none\" points=\"315,-.5 315,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"373.5\" y=\"-8.3\">(None, 886, 128)</text>\n</g>\n<!-- 140655425221912&#45;&gt;140655425221520 -->\n<g class=\"edge\" id=\"edge1\">\n<title>140655425221912-&gt;140655425221520</title>\n<path d=\"M192.1898,-35C200.6158,-35 209.1906,-35 217.7317,-35\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"217.7319,-38.5001 227.7319,-35 217.7318,-31.5001 217.7319,-38.5001\" stroke=\"#000000\"/>\n</g>\n<!-- 140655426937128 -->\n<g class=\"node\" id=\"node3\">\n<title>140655426937128</title>\n<polygon fill=\"none\" points=\"468,-.5 468,-69.5 702,-69.5 702,-.5 468,-.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"585\" y=\"-54.3\">SpatialDropout1D</text>\n<polyline fill=\"none\" points=\"468,-46.5 702,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"524.5\" y=\"-31.3\">input:</text>\n<polyline fill=\"none\" points=\"581,-23.5 581,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"641.5\" y=\"-31.3\">output:</text>\n<polyline fill=\"none\" points=\"468,-23.5 702,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"526.5\" y=\"-8.3\">(None, 886, 128)</text>\n<polyline fill=\"none\" points=\"585,-.5 585,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"643.5\" y=\"-8.3\">(None, 886, 128)</text>\n</g>\n<!-- 140655425221520&#45;&gt;140655426937128 -->\n<g class=\"edge\" id=\"edge2\">\n<title>140655425221520-&gt;140655426937128</title>\n<path d=\"M432.249,-35C440.5236,-35 448.9461,-35 457.3693,-35\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"457.6343,-38.5001 467.6343,-35 457.6343,-31.5001 457.6343,-38.5001\" stroke=\"#000000\"/>\n</g>\n<!-- 140655426937016 -->\n<g class=\"node\" id=\"node4\">\n<title>140655426937016</title>\n<polygon fill=\"none\" points=\"738,-.5 738,-69.5 935,-69.5 935,-.5 738,-.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"836.5\" y=\"-54.3\">LSTM</text>\n<polyline fill=\"none\" points=\"738,-46.5 935,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"785\" y=\"-31.3\">input:</text>\n<polyline fill=\"none\" points=\"832,-23.5 832,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"883.5\" y=\"-31.3\">output:</text>\n<polyline fill=\"none\" points=\"738,-23.5 935,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"796.5\" y=\"-8.3\">(None, 886, 128)</text>\n<polyline fill=\"none\" points=\"855,-.5 855,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"895\" y=\"-8.3\">(None, 64)</text>\n</g>\n<!-- 140655426937128&#45;&gt;140655426937016 -->\n<g class=\"edge\" id=\"edge3\">\n<title>140655426937128-&gt;140655426937016</title>\n<path d=\"M702.2823,-35C710.7493,-35 719.2677,-35 727.6831,-35\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"727.8865,-38.5001 737.8865,-35 727.8865,-31.5001 727.8865,-38.5001\" stroke=\"#000000\"/>\n</g>\n<!-- 140655698004848 -->\n<g class=\"node\" id=\"node5\">\n<title>140655698004848</title>\n<polygon fill=\"none\" points=\"971,-.5 971,-69.5 1123,-69.5 1123,-.5 971,-.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1047\" y=\"-54.3\">Dense</text>\n<polyline fill=\"none\" points=\"971,-46.5 1123,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1007\" y=\"-31.3\">input:</text>\n<polyline fill=\"none\" points=\"1043,-23.5 1043,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1083\" y=\"-31.3\">output:</text>\n<polyline fill=\"none\" points=\"971,-23.5 1123,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1011\" y=\"-8.3\">(None, 64)</text>\n<polyline fill=\"none\" points=\"1051,-.5 1051,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1087\" y=\"-8.3\">(None, 1)</text>\n</g>\n<!-- 140655426937016&#45;&gt;140655698004848 -->\n<g class=\"edge\" id=\"edge4\">\n<title>140655426937016-&gt;140655698004848</title>\n<path d=\"M935.2783,-35C943.7837,-35 952.3458,-35 960.7411,-35\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"960.8838,-38.5001 970.8838,-35 960.8838,-31.5001 960.8838,-38.5001\" stroke=\"#000000\"/>\n</g>\n</g>\n</svg>"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3k9Es-0jebia",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0334155-e754-4837-b5ce-bbfdbe91648e"
      },
      "source": [
        "batch_size = 100\n",
        "model.fit(train_X, train_y, epochs=3, batch_size=batch_size, shuffle=True, validation_split=0.1, verbose=1)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "221/221 [==============================] - 514s 2s/step - loss: 0.5092 - accuracy: 0.7561 - val_loss: 0.3200 - val_accuracy: 0.8649\n",
            "Epoch 2/3\n",
            "221/221 [==============================] - 508s 2s/step - loss: 0.2675 - accuracy: 0.8944 - val_loss: 0.3118 - val_accuracy: 0.8727\n",
            "Epoch 3/3\n",
            "221/221 [==============================] - 509s 2s/step - loss: 0.2015 - accuracy: 0.9238 - val_loss: 0.3436 - val_accuracy: 0.8641\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fece4b41390>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "id": "J4kZlT8DyBSG",
        "outputId": "a456ea7e-4956-4597-c411-8397e51b3d96"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "\n",
        "pred_test = model.predict_classes(test_X)\n",
        "y_predicted = le.inverse_transform(pred_test.flatten())\n",
        "\n",
        "print(\"The model accuracy score is: {}\".format(accuracy_score(test_Label, y_predicted)))\n",
        "print(\"The model precision score is: {}\".format(precision_score(test_Label, y_predicted, average=\"weighted\")))\n",
        "print(\"The model recall score is: {}\".format(recall_score(test_Label, y_predicted, average=\"weighted\")))\n",
        "print(\"The model F1-score is: {}\".format(f1_score(test_Label, y_predicted, average=\"weighted\")))\n",
        "\n",
        "print(classification_report(test_Label, y_predicted))\n",
        "\n",
        "display(pd.DataFrame(confusion_matrix(test_Label, y_predicted), columns=[\"Pred. negative\", \"Pred. positive\"], index=[\"Act. negative\", \"Act. positive\"]))"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "The model accuracy score is: 0.8571428571428571\n",
            "The model precision score is: 0.8537411031113593\n",
            "The model recall score is: 0.8571428571428571\n",
            "The model F1-score is: 0.8542802627795957\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.69      0.73      2973\n",
            "           1       0.88      0.92      0.90      7527\n",
            "\n",
            "    accuracy                           0.86     10500\n",
            "   macro avg       0.83      0.81      0.82     10500\n",
            "weighted avg       0.85      0.86      0.85     10500\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pred. negative</th>\n",
              "      <th>Pred. positive</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Act. negative</th>\n",
              "      <td>2047</td>\n",
              "      <td>926</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Act. positive</th>\n",
              "      <td>574</td>\n",
              "      <td>6953</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               Pred. negative  Pred. positive\n",
              "Act. negative            2047             926\n",
              "Act. positive             574            6953"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hs7uF6jDemKN"
      },
      "source": [
        "import pickle"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NdRSbi1itnn7"
      },
      "source": [
        "pkl_filename = 'SVM_Model.pkl'\n",
        "with open('svm_pickle', 'wb') as f:\n",
        "  pickle.dump(svm, f)"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X144ty-dvQpA"
      },
      "source": [
        "with open('svm_pickle', 'rb') as f:\n",
        "  np = pickle.load(f)\n"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HRgKTYu30Noj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}